{"status":"ok","feed":{"url":"https://medium.com/feed/@@gaurlokesh1211","title":"Stories by Lokesh Gaur on Medium","link":"https://medium.com/@gaurlokesh1211?source=rss-520cb1ddc1ca------2","author":"","description":"Stories by Lokesh Gaur on Medium","image":"https://cdn-images-1.medium.com/fit/c/150/150/1*GOSU-AhRN3FTYm5J-RtiLg.png"},"items":[{"title":"Web Scraping of \u201c99Acres Real Estate Property\u201d using Selenium","pubDate":"2025-06-27 13:58:08","link":"https://medium.com/@gaurlokesh1211/web-scraping-of-99acres-real-estate-property-using-selenium-3105102f733b?source=rss-520cb1ddc1ca------2","guid":"https://medium.com/p/3105102f733b","author":"Lokesh Gaur","thumbnail":"","description":"\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*_aIxAcPHpdhvgaJFJOBmDw.png\"></figure><p><strong>99acres</strong> is one of India\u2019s real estate platforms, providing a digital space where users can buy, sell, or rent properties.</p>\n<p>The page<a href=\"https://www.99acres.com/\"> <strong>https://www.99acres.com</strong></a> provides a list of the properties on 99acres. In this article we\u2019ll retrieve information about properties in Chennai using web scraping (<em>the process of extracting information from a website in an automated fashion using code)</em>. We\u2019ll use the Python libraries <a href=\"https://www.selenium.dev/documentation/\"><strong><em>Selenium</em></strong></a><strong><em> (</em></strong><em>enables and support the automation of web browsers</em><strong><em>) </em></strong>to scrap data and <a href=\"https://pandas.pydata.org/docs/user_guide/index.html\"><strong><em>Pandas</em></strong></a><strong><em>, </em></strong><a href=\"https://numpy.org/doc/stable/user/\"><strong><em>NumP</em></strong></a>y in order to clean and manipulate the\u00a0data<strong><em>.</em></strong></p>\n<p>Here\u2019s a step-by-step outline of this\u00a0project:</p>\n<ol>\n<li>Set browser Options before initiating the web\u00a0driver.</li>\n<li>Visit the target URL: <a href=\"https://www.99acres.com/\">https://www.99acres.com</a>.</li>\n<li>Type Chennai in the search\u00a0bar.</li>\n<li>Click on Search\u00a0button.</li>\n<li>Search button Adjust the Budget slider to 5cr\u00a0INR.</li>\n<li>Click on the below options to filter the resulting data:<br>i. Verified.<br>ii. Ready To Move<br>iii. With Photos.<br>iv. With\u00a0Videos.</li>\n<li>Navigate pages, Scrape the necessary data: <em>name, location, price, area and\u00a0bhk.</em>\n</li>\n<li>clean and Export data as an Excel\u00a0sheet.</li>\n</ol>\n<blockquote>You can view complete code here:\u200a\u2014\u200a<a href=\"https://github.com/gaur8126/99acres_Web_Scraping.git\">https://github.com/gaur8126/99acres_Web_Scraping.git</a>\n</blockquote>\n<h3><strong>Set browser Options before initiating the web\u00a0driver</strong></h3>\n<p>To begin, we\u2019ll use selenium Python library to load and download the web page <a href=\"https://www.99acres.com/\">https://www.99acres.com</a></p>\n<p><a href=\"https://www.selenium.dev/documentation/\">The Selenium Browser Automation Project</a></p>\n<p>Let\u2019s install and import necessary dependencies.</p>\n<pre>!pip install selenium<br>!pip install pandas <br>!pip install numpy </pre>\n<pre>import time <br>import pandas as pd <br>import numpy as np <br>import selenium<br>from selenium.webdriver.chrome.options import Options</pre>\n<p>Websites often restrict access to bots or automated tools like Selenium so you can use these options that provide control and flexibility in web automation.</p>\n<pre>chrome_options = Options()<br>chrome_options.add_argument(\"--disable-http2\")<br>chrome_options.add_argument(\"--incognito\")<br>chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")<br>chrome_options.add_argument(\"--ignore-certificate-errors\")<br>chrome_options.add_argument(\"--enable-features=NetworkServiceInProcess\")<br>chrome_options.add_argument(\"--disable-features=NetworkService\")<br>chrome_options.add_argument(<br>    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36\"<br>)</pre>\n<p>To know more about Options()visit: <a href=\"https://www.selenium.dev/documentation/webdriver/drivers/options/\">Browser Options |\u00a0Selenium</a></p>\n<blockquote>\n<strong>Note:</strong> Here, we are using Chrome browser but each browser driver has its own Options class. You can change according to your\u00a0browser.</blockquote>\n<h3>\n<strong>Visit the target URL: </strong><a href=\"https://www.99acres.com./\"><strong>https://www.99acres.com.</strong></a>\n</h3>\n<p>We\u2019ll use <a href=\"https://www.selenium.dev/documentation/webdriver/\">webdriver.Chrome</a> function to initialize chrome browser and pass all the options which we defined in previous\u00a0section.</p>\n<pre>from selenium import webdriver<br>from selenium.webdriver.support.ui import WebDriverWait</pre>\n<ul><li>\n<a href=\"https://www.geeksforgeeks.org/software-testing/how-to-get-selenium-to-wait-for-a-page-to-load/\">WebDriverWait</a><em> ensuring that web pages fully load before interacting with\u00a0elements</em>\n</li></ul>\n<p>We\u2019ll use driver.get to load the\u00a0page.</p>\n<pre>driver = webdriver.Chrome(options=chrome_options)<br>driver.maximize_window() # Maximize the browser's window<br><br># explicit wait <br>wait = WebDriverWait(driver,5)<br><br># accessing the target web page <br>url = \"https://www.99acres.com/\"<br>driver.get(url)</pre>\n<h3><strong>Type Chennai in the search\u00a0bar.</strong></h3>\n<p>Let\u2019s import necessary dependencies.</p>\n<pre>from selenium.webdriver.common.by import By<br>from selenium.webdriver.common.keys import Keys<br>from selenium.webdriver.support import expected_conditions as EC</pre>\n<ul>\n<li>\n<a href=\"https://www.selenium.dev/selenium/docs/api/py/webdriver/selenium.webdriver.common.by.html?form=MG0AV3\">By</a>: \u201cSet of supported locator strategies\u201d that tells Selenium <em>how</em> to find an element on a\u00a0webpage.</li>\n<li>\n<a href=\"https://www.geeksforgeeks.org/special-keys-in-selenium-python/\">Keys</a>: allows pressing keys through\u00a0keyboard</li>\n<li>\n<a href=\"https://www.geeksforgeeks.org/software-testing/expected-conditions-in-selenium-with-types-and-examples/\">expected_conditions|EC</a>: help \u201c<strong>wait for specific conditions\u201d</strong> to be met before proceeding with further actions, ensuring that elements are present, visible, or in a specific\u00a0state.</li>\n</ul>\n<p>This script will attempt to locate a search bar on a web page (identified by a specific <a href=\"https://www.geeksforgeeks.org/javascript/introduction-to-xpath/\">XPath</a>: <em>commonly used to find the web elements</em>) and then type the word \u201cChennai\u201d into\u00a0it.</p>\n<pre># identify and enter text into search bar <br><br>try:<br>    search_bar = wait.until(<br>        EC.presence_of_element_located((By.XPATH,'//*[@id=\"keyword2\"]'))<br>    )<br>except:<br>    print(\"Timeout while locating Seach Bar.\\n\")<br>else:<br>    search_bar.send_keys(\"Chennai\")<br>    time.sleep(2)</pre>\n<ul>\n<li>wait.until(): waits until a certain condition is\u00a0met.</li>\n<li>EC.presence_of_element_located: This is an expected condition\u200a\u2014\u200ait checks whether the element is in the <a href=\"https://www.geeksforgeeks.org/dom-document-object-model/\">DOM (Document Object\u00a0Model)</a>\n</li>\n<li>search_bar.send_keys: sending the text \u201cChennai\u201d to the search_bar input\u00a0field.</li>\n</ul>\n<h3>Click on Search\u00a0button.</h3>\n<p>In this section we\u2019ll check not only the presence the of search button also it is clickable.</p>\n<pre># click on search button <br>try:<br>    search_button = wait.until(<br>        EC.element_to_be_clickable((By.XPATH,'//*[@id=\"searchform_search_btn\"]'))<br>    )<br>except:<br>    print(\"Timeout while clicking the seach button\")<br>else:<br>    search_button.click()<br>    wait_for_page_to_load(driver,wait)</pre>\n<p>wait.until checks the presence of search button, Ec.element_to_be_clickable checks whether the button clickable or not if yes then search_button.click click the\u00a0button.</p>\n<h3>Adjust the Budget slider to 5cr\u00a0INR.</h3>\n<p>Now we\u2019ll adjust the budget slider to search the properties up to 5cr\u00a0INR.</p>\n<pre>from selenium.webdriver.common.action_chains import ActionChains</pre>\n<ul><li>\n<a href=\"https://www.selenium.dev/selenium/docs/api/py/webdriver/selenium.webdriver.common.action_chains.html\">ActionChains</a>: are a way to automate low level interactions such as mouse movements, mouse button actions, key press, and context menu interactions.</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/461/1*7vWsH1UHtcPdDFcQNDfvTw.png\"><figcaption>Before\u00a0.</figcaption></figure><pre>## adjust the budget slider <br><br>try:<br>    slider =  wait.until(<br>        EC.element_to_be_clickable((By.XPATH,'//*[@id=\"budgetLeftFilter_max_node\"]'))<br>    )<br><br>except:<br>    print(\"Timeout while clicking on budget slider circle.\\n\")<br>else:<br>    actions = ActionChains(driver)<br>    (<br>        actions<br>        .click_and_hold(slider)<br>        .move_by_offset(-73,0)<br>        .release()<br>        .perform()<br>    )<br>    time.sleep(2)</pre>\n<p>It performs a <strong>click-and-drag motion</strong> on a web element (in this case on a slider), moves it horizontally to the left by<strong> 73 pixels</strong>, and then releases\u00a0it.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/453/1*tWXMg_F3mpcx96Hl2xkRXg.png\"><figcaption>After\u00a0.</figcaption></figure><h3><strong>Click on the below options to filter the resulting data</strong></h3>\n<p>There are several filters on \u201c<a href=\"https://www.99acres.com/\">https://www.99acres.com/</a>\u201d page, we\u2019ll apply four of them. Those\u00a0are:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/979/1*__pfc2VE5VDambPqGedyLA.png\"><figcaption>Like this</figcaption></figure><ol><li>Verified</li></ol>\n<pre>verified = wait.until(<br>    EC.element_to_be_clickable((By.XPATH,'/html[1]/body[1]/div[1]/div[1]/div[1]/div[4]/div[3]/div[1]/div[3]/section[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[3]/span[2]'))<br>)<br>verified.click()<br>time.sleep(1)</pre>\n<p>2. Ready To\u00a0Move</p>\n<pre>ready_to_move = wait.until(<br>    EC.element_to_be_clickable((By.XPATH,'/html[1]/body[1]/div[1]/div[1]/div[1]/div[4]/div[3]/div[1]/div[3]/section[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[5]/span[2]'))<br>)<br>ready_to_move.click()<br>time.sleep(2)</pre>\n<p>Moving to the right side to unhide remaining filters\u00a0:)</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/979/1*7dAppZ7f4pGLRC71rkqNkw.png\"><figcaption><strong>Before</strong></figcaption></figure><pre>while True:<br>    try:<br>        filter_right_button = wait.until(<br>            EC.presence_of_element_located((By.XPATH,\"//i[@class='iconS_Common_24 icon_upArrow cc__rightArrow']\"))<br>        )<br>    except:<br>        print(\"Timeout because we have uncovered all filers\")<br>        break<br><br>    else:<br>        filter_right_button.click()<br>        time.sleep(2)</pre>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*OFM0s5FNFYeu7e3EhVXPqw.png\"><figcaption><strong>After</strong></figcaption></figure><p>3. With\u00a0Photos</p>\n<pre>try:<br>    with_photos = wait.until(<br>        EC.element_to_be_clickable((By.XPATH,\"//span[normalize-space()='With Photos']\"))<br>    ) <br>except :<br>    print(\"Timeout while click the option\")<br>else:<br>    with_photos.click()<br>    time.sleep(2)</pre>\n<p>4. With\u00a0Videos</p>\n<pre>try:<br>    with_videos = wait.until(<br>        EC.element_to_be_clickable((By.XPATH,\"//span[normalize-space()='With Videos']\"))<br>    )<br>except:<br>     print(\"Timeout while click the option\")<br>else:<br>    with_videos.click()<br>    time.sleep(3)</pre>\n<h3>Navigate pages, Scrape the necessary data: <em>name, location, price, area and\u00a0bhk.</em>\n</h3>\n<p>In this section we\u2019ll navigate to each page one by one and extract the name of property owner, location, the price of property and\u00a0BHK.</p>\n<pre>while True:<br>    try:<br>        time.sleep(3)<br>        next_page_button = driver.find_element(By.XPATH,\"//a[normalize-space()='Next Page &gt;']\")<br>    except:<br>        print(f\"Timeout because we have navigated all the {page_count} pages.\\n\")<br>        break<br>    else:<br>        print(\"entered Else block\")<br>        try:<br>            driver.execute_script(\"window.scrollBy(0, arguments[0].getBoundingClientRect().top - 100);\", next_page_button)<br>            time.sleep(2)<br><br>            ## scraping the data <br>            rows = driver.find_elements(By.CLASS_NAME,\"tupleNew__contentWrap\")<br>            for row in rows:<br>                ## property name<br>                try:<br>                    name = row.find_element(By.CLASS_NAME,\"tupleNew__headingNrera\").text<br>                except:<br>                    name = np.nan<br><br>                ## property location <br>                try:<br>                    location = row.find_element(By.CLASS_NAME,\"tupleNew__propType\").text<br>                except:<br>                    location = np.nan<br><br>                ## property price     <br>                try:<br>                    price = row.find_element(By.CLASS_NAME,\"tupleNew__priceValWrap\").text<br>                except:<br>                    price = np.nan<br><br>                ## property area and size(bhk) <br>                try:<br>                    elements = row.find_elements(By.CLASS_NAME,\"tupleNew__area1Type\")<br>                except:<br>                    area,bhk = [np.nan,np.nan]<br>                else:<br>                    area,bhk = [ele.text for ele in elements]<br><br>                property = {<br>                    \"name\":name,<br>                    \"location\":location,<br>                    \"price\":price,<br>                    \"area\":area,<br>                    \"bhk\":bhk<br>                }<br>                data.append(property)<br><br>            wait.until(<br>                EC.element_to_be_clickable((By.XPATH, \"//a[normalize-space()='Next Page &gt;']\"))<br>            ).click()<br>            # time.sleep(5)<br>        except :<br>            print(\"Timeout while clicking on \\\"Next Page\\\".\\n\")</pre>\n<pre>time.sleep(3)<br>next_page_button = driver.find_element(By.XPATH,\"//a[normalize-space()='Next Page &gt;']\")</pre>\n<p>Pauses 3 seconds, then tries to find the \u201cNext Page\u201d\u00a0button.</p>\n<pre>driver.execute_script(\"window.scrollBy(0, arguments[0].getBoundingClientRect().top - 100);\", next_page_button)</pre>\n<p>Scrolls the page to the button\u2019s location.</p>\n<h3>clean and Export data as an Excel\u00a0sheet.</h3>\n<p>To clean and export data as an excel, will use Pandas\u00a0library.</p>\n<pre>df_properties = (<br>    pd<br>    .DataFrame(data)<br>    .drop_duplicates()<br>    .apply(lambda col: col.str.strip().str.lower() if col.dtype == \"object\" else col)<br>    .assign(<br>        is_starred = lambda df_:df_.name.str.contains(\"\\n\").astype(int),<br>        name = lambda df_ :(<br>            df_<br>            .name<br>            .str.replace(\"\\n[0-9.]+\",\"\",regex=True)<br>            .str.strip()<br>        ),<br>        location = lambda df_:(<br>            df_<br>            .location<br>            .str.replace(\"chennai\",\"\")<br>            .str.strip()<br>            .str.replace(\",$\",\"\",regex=True)<br>            .str.split(\"in\")<br>            .str[-1]<br>            .str.strip()<br>        ),<br>        price = lambda df_ :(<br>            df_<br>            .price<br>            .str.replace(\"\u20b9\",\"\")<br>            .apply(lambda val: float(val.replace(\"lac\",\"\").strip()) if \"lac\" in val else float(val.replace(\"cr\",\"\").strip())*100)<br>        ),<br>        area = lambda df_ : (<br>            df_<br>            .area<br>            .str.replace(\"sqft\",\"\")<br>            .str.strip()<br>            .str.replace(\",\",\"\")<br>            .pipe(lambda ser:pd.to_numeric(ser))<br>        ),<br>        bhk = lambda df_ : (<br>            df_<br>            .bhk<br>            .str.replace(\"bhk\",\"\")<br>            .str.strip()<br>            .pipe(lambda ser:pd.to_numeric(ser))<br><br>        )<br>    )<br>    .rename(columns={<br>        \"price\":\"price_lakhs\",<br>        \"area\":\"area_sqft\"<br>    })<br>    .reset_index(drop=True)<br>    .to_excel(\"chennai-properties-99acres.xlsx\",index=False)<br>)<br># df_properties.query(\"is_starred == 1\")<br>df_properties </pre>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zN17jzg98zzs_Iflci2D9w.png\"><figcaption>output</figcaption></figure><h3><strong>Summary</strong></h3>\n<p>Here is brief summary of step-by-step process we followed for scraping properties from\u00a099acres.</p>\n<ol>\n<li>We saw websites often restrict access to bots or automated tools like Selenium so we set \u2018<a href=\"https://www.selenium.dev/documentation/webdriver/drivers/options/\">Options\u2019</a> to provide control and flexibility in web automation.</li>\n<li>Visited target URL \u201c<a href=\"https://www.99acres.com./\">https://www.99acres.com</a>\u201d by usingdriver.get(url).</li>\n<li>Attempted to locate a search bar on a web page and then typed the word \u201cChennai\u201d into\u00a0it.</li>\n<li>Not only checked the presence of search button also clicked the\u00a0button.</li>\n<li>Adjusted the budget slider to search the properties up to 5cr\u00a0INR.</li>\n<li>We applied 4 filters\u00a0: Verified, Ready To Move, With Photos and With\u00a0Videos.</li>\n<li>Navigated to each page one by one and extracted the name of property owner, location, the price of property and\u00a0BHK.</li>\n<li>Cleaned and exported the data as excel\u00a0file.</li>\n</ol>\n<h3><strong>References:</strong></h3>\n<p><a href=\"https://www.selenium.dev/documentation/\"><em>The Selenium Browser Automation Project.</em></a></p>\n<p><a href=\"https://www.geeksforgeeks.org/selenium-python-tutorial/\"><em>Selenium Python Tutorial Geeks For\u00a0Geeks.</em></a></p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=3105102f733b\" width=\"1\" height=\"1\" alt=\"\">\n","content":"\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*_aIxAcPHpdhvgaJFJOBmDw.png\"></figure><p><strong>99acres</strong> is one of India\u2019s real estate platforms, providing a digital space where users can buy, sell, or rent properties.</p>\n<p>The page<a href=\"https://www.99acres.com/\"> <strong>https://www.99acres.com</strong></a> provides a list of the properties on 99acres. In this article we\u2019ll retrieve information about properties in Chennai using web scraping (<em>the process of extracting information from a website in an automated fashion using code)</em>. We\u2019ll use the Python libraries <a href=\"https://www.selenium.dev/documentation/\"><strong><em>Selenium</em></strong></a><strong><em> (</em></strong><em>enables and support the automation of web browsers</em><strong><em>) </em></strong>to scrap data and <a href=\"https://pandas.pydata.org/docs/user_guide/index.html\"><strong><em>Pandas</em></strong></a><strong><em>, </em></strong><a href=\"https://numpy.org/doc/stable/user/\"><strong><em>NumP</em></strong></a>y in order to clean and manipulate the\u00a0data<strong><em>.</em></strong></p>\n<p>Here\u2019s a step-by-step outline of this\u00a0project:</p>\n<ol>\n<li>Set browser Options before initiating the web\u00a0driver.</li>\n<li>Visit the target URL: <a href=\"https://www.99acres.com/\">https://www.99acres.com</a>.</li>\n<li>Type Chennai in the search\u00a0bar.</li>\n<li>Click on Search\u00a0button.</li>\n<li>Search button Adjust the Budget slider to 5cr\u00a0INR.</li>\n<li>Click on the below options to filter the resulting data:<br>i. Verified.<br>ii. Ready To Move<br>iii. With Photos.<br>iv. With\u00a0Videos.</li>\n<li>Navigate pages, Scrape the necessary data: <em>name, location, price, area and\u00a0bhk.</em>\n</li>\n<li>clean and Export data as an Excel\u00a0sheet.</li>\n</ol>\n<blockquote>You can view complete code here:\u200a\u2014\u200a<a href=\"https://github.com/gaur8126/99acres_Web_Scraping.git\">https://github.com/gaur8126/99acres_Web_Scraping.git</a>\n</blockquote>\n<h3><strong>Set browser Options before initiating the web\u00a0driver</strong></h3>\n<p>To begin, we\u2019ll use selenium Python library to load and download the web page <a href=\"https://www.99acres.com/\">https://www.99acres.com</a></p>\n<p><a href=\"https://www.selenium.dev/documentation/\">The Selenium Browser Automation Project</a></p>\n<p>Let\u2019s install and import necessary dependencies.</p>\n<pre>!pip install selenium<br>!pip install pandas <br>!pip install numpy </pre>\n<pre>import time <br>import pandas as pd <br>import numpy as np <br>import selenium<br>from selenium.webdriver.chrome.options import Options</pre>\n<p>Websites often restrict access to bots or automated tools like Selenium so you can use these options that provide control and flexibility in web automation.</p>\n<pre>chrome_options = Options()<br>chrome_options.add_argument(\"--disable-http2\")<br>chrome_options.add_argument(\"--incognito\")<br>chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")<br>chrome_options.add_argument(\"--ignore-certificate-errors\")<br>chrome_options.add_argument(\"--enable-features=NetworkServiceInProcess\")<br>chrome_options.add_argument(\"--disable-features=NetworkService\")<br>chrome_options.add_argument(<br>    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36\"<br>)</pre>\n<p>To know more about Options()visit: <a href=\"https://www.selenium.dev/documentation/webdriver/drivers/options/\">Browser Options |\u00a0Selenium</a></p>\n<blockquote>\n<strong>Note:</strong> Here, we are using Chrome browser but each browser driver has its own Options class. You can change according to your\u00a0browser.</blockquote>\n<h3>\n<strong>Visit the target URL: </strong><a href=\"https://www.99acres.com./\"><strong>https://www.99acres.com.</strong></a>\n</h3>\n<p>We\u2019ll use <a href=\"https://www.selenium.dev/documentation/webdriver/\">webdriver.Chrome</a> function to initialize chrome browser and pass all the options which we defined in previous\u00a0section.</p>\n<pre>from selenium import webdriver<br>from selenium.webdriver.support.ui import WebDriverWait</pre>\n<ul><li>\n<a href=\"https://www.geeksforgeeks.org/software-testing/how-to-get-selenium-to-wait-for-a-page-to-load/\">WebDriverWait</a><em> ensuring that web pages fully load before interacting with\u00a0elements</em>\n</li></ul>\n<p>We\u2019ll use driver.get to load the\u00a0page.</p>\n<pre>driver = webdriver.Chrome(options=chrome_options)<br>driver.maximize_window() # Maximize the browser's window<br><br># explicit wait <br>wait = WebDriverWait(driver,5)<br><br># accessing the target web page <br>url = \"https://www.99acres.com/\"<br>driver.get(url)</pre>\n<h3><strong>Type Chennai in the search\u00a0bar.</strong></h3>\n<p>Let\u2019s import necessary dependencies.</p>\n<pre>from selenium.webdriver.common.by import By<br>from selenium.webdriver.common.keys import Keys<br>from selenium.webdriver.support import expected_conditions as EC</pre>\n<ul>\n<li>\n<a href=\"https://www.selenium.dev/selenium/docs/api/py/webdriver/selenium.webdriver.common.by.html?form=MG0AV3\">By</a>: \u201cSet of supported locator strategies\u201d that tells Selenium <em>how</em> to find an element on a\u00a0webpage.</li>\n<li>\n<a href=\"https://www.geeksforgeeks.org/special-keys-in-selenium-python/\">Keys</a>: allows pressing keys through\u00a0keyboard</li>\n<li>\n<a href=\"https://www.geeksforgeeks.org/software-testing/expected-conditions-in-selenium-with-types-and-examples/\">expected_conditions|EC</a>: help \u201c<strong>wait for specific conditions\u201d</strong> to be met before proceeding with further actions, ensuring that elements are present, visible, or in a specific\u00a0state.</li>\n</ul>\n<p>This script will attempt to locate a search bar on a web page (identified by a specific <a href=\"https://www.geeksforgeeks.org/javascript/introduction-to-xpath/\">XPath</a>: <em>commonly used to find the web elements</em>) and then type the word \u201cChennai\u201d into\u00a0it.</p>\n<pre># identify and enter text into search bar <br><br>try:<br>    search_bar = wait.until(<br>        EC.presence_of_element_located((By.XPATH,'//*[@id=\"keyword2\"]'))<br>    )<br>except:<br>    print(\"Timeout while locating Seach Bar.\\n\")<br>else:<br>    search_bar.send_keys(\"Chennai\")<br>    time.sleep(2)</pre>\n<ul>\n<li>wait.until(): waits until a certain condition is\u00a0met.</li>\n<li>EC.presence_of_element_located: This is an expected condition\u200a\u2014\u200ait checks whether the element is in the <a href=\"https://www.geeksforgeeks.org/dom-document-object-model/\">DOM (Document Object\u00a0Model)</a>\n</li>\n<li>search_bar.send_keys: sending the text \u201cChennai\u201d to the search_bar input\u00a0field.</li>\n</ul>\n<h3>Click on Search\u00a0button.</h3>\n<p>In this section we\u2019ll check not only the presence the of search button also it is clickable.</p>\n<pre># click on search button <br>try:<br>    search_button = wait.until(<br>        EC.element_to_be_clickable((By.XPATH,'//*[@id=\"searchform_search_btn\"]'))<br>    )<br>except:<br>    print(\"Timeout while clicking the seach button\")<br>else:<br>    search_button.click()<br>    wait_for_page_to_load(driver,wait)</pre>\n<p>wait.until checks the presence of search button, Ec.element_to_be_clickable checks whether the button clickable or not if yes then search_button.click click the\u00a0button.</p>\n<h3>Adjust the Budget slider to 5cr\u00a0INR.</h3>\n<p>Now we\u2019ll adjust the budget slider to search the properties up to 5cr\u00a0INR.</p>\n<pre>from selenium.webdriver.common.action_chains import ActionChains</pre>\n<ul><li>\n<a href=\"https://www.selenium.dev/selenium/docs/api/py/webdriver/selenium.webdriver.common.action_chains.html\">ActionChains</a>: are a way to automate low level interactions such as mouse movements, mouse button actions, key press, and context menu interactions.</li></ul>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/461/1*7vWsH1UHtcPdDFcQNDfvTw.png\"><figcaption>Before\u00a0.</figcaption></figure><pre>## adjust the budget slider <br><br>try:<br>    slider =  wait.until(<br>        EC.element_to_be_clickable((By.XPATH,'//*[@id=\"budgetLeftFilter_max_node\"]'))<br>    )<br><br>except:<br>    print(\"Timeout while clicking on budget slider circle.\\n\")<br>else:<br>    actions = ActionChains(driver)<br>    (<br>        actions<br>        .click_and_hold(slider)<br>        .move_by_offset(-73,0)<br>        .release()<br>        .perform()<br>    )<br>    time.sleep(2)</pre>\n<p>It performs a <strong>click-and-drag motion</strong> on a web element (in this case on a slider), moves it horizontally to the left by<strong> 73 pixels</strong>, and then releases\u00a0it.</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/453/1*tWXMg_F3mpcx96Hl2xkRXg.png\"><figcaption>After\u00a0.</figcaption></figure><h3><strong>Click on the below options to filter the resulting data</strong></h3>\n<p>There are several filters on \u201c<a href=\"https://www.99acres.com/\">https://www.99acres.com/</a>\u201d page, we\u2019ll apply four of them. Those\u00a0are:</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/979/1*__pfc2VE5VDambPqGedyLA.png\"><figcaption>Like this</figcaption></figure><ol><li>Verified</li></ol>\n<pre>verified = wait.until(<br>    EC.element_to_be_clickable((By.XPATH,'/html[1]/body[1]/div[1]/div[1]/div[1]/div[4]/div[3]/div[1]/div[3]/section[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[3]/span[2]'))<br>)<br>verified.click()<br>time.sleep(1)</pre>\n<p>2. Ready To\u00a0Move</p>\n<pre>ready_to_move = wait.until(<br>    EC.element_to_be_clickable((By.XPATH,'/html[1]/body[1]/div[1]/div[1]/div[1]/div[4]/div[3]/div[1]/div[3]/section[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[5]/span[2]'))<br>)<br>ready_to_move.click()<br>time.sleep(2)</pre>\n<p>Moving to the right side to unhide remaining filters\u00a0:)</p>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/979/1*7dAppZ7f4pGLRC71rkqNkw.png\"><figcaption><strong>Before</strong></figcaption></figure><pre>while True:<br>    try:<br>        filter_right_button = wait.until(<br>            EC.presence_of_element_located((By.XPATH,\"//i[@class='iconS_Common_24 icon_upArrow cc__rightArrow']\"))<br>        )<br>    except:<br>        print(\"Timeout because we have uncovered all filers\")<br>        break<br><br>    else:<br>        filter_right_button.click()<br>        time.sleep(2)</pre>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*OFM0s5FNFYeu7e3EhVXPqw.png\"><figcaption><strong>After</strong></figcaption></figure><p>3. With\u00a0Photos</p>\n<pre>try:<br>    with_photos = wait.until(<br>        EC.element_to_be_clickable((By.XPATH,\"//span[normalize-space()='With Photos']\"))<br>    ) <br>except :<br>    print(\"Timeout while click the option\")<br>else:<br>    with_photos.click()<br>    time.sleep(2)</pre>\n<p>4. With\u00a0Videos</p>\n<pre>try:<br>    with_videos = wait.until(<br>        EC.element_to_be_clickable((By.XPATH,\"//span[normalize-space()='With Videos']\"))<br>    )<br>except:<br>     print(\"Timeout while click the option\")<br>else:<br>    with_videos.click()<br>    time.sleep(3)</pre>\n<h3>Navigate pages, Scrape the necessary data: <em>name, location, price, area and\u00a0bhk.</em>\n</h3>\n<p>In this section we\u2019ll navigate to each page one by one and extract the name of property owner, location, the price of property and\u00a0BHK.</p>\n<pre>while True:<br>    try:<br>        time.sleep(3)<br>        next_page_button = driver.find_element(By.XPATH,\"//a[normalize-space()='Next Page &gt;']\")<br>    except:<br>        print(f\"Timeout because we have navigated all the {page_count} pages.\\n\")<br>        break<br>    else:<br>        print(\"entered Else block\")<br>        try:<br>            driver.execute_script(\"window.scrollBy(0, arguments[0].getBoundingClientRect().top - 100);\", next_page_button)<br>            time.sleep(2)<br><br>            ## scraping the data <br>            rows = driver.find_elements(By.CLASS_NAME,\"tupleNew__contentWrap\")<br>            for row in rows:<br>                ## property name<br>                try:<br>                    name = row.find_element(By.CLASS_NAME,\"tupleNew__headingNrera\").text<br>                except:<br>                    name = np.nan<br><br>                ## property location <br>                try:<br>                    location = row.find_element(By.CLASS_NAME,\"tupleNew__propType\").text<br>                except:<br>                    location = np.nan<br><br>                ## property price     <br>                try:<br>                    price = row.find_element(By.CLASS_NAME,\"tupleNew__priceValWrap\").text<br>                except:<br>                    price = np.nan<br><br>                ## property area and size(bhk) <br>                try:<br>                    elements = row.find_elements(By.CLASS_NAME,\"tupleNew__area1Type\")<br>                except:<br>                    area,bhk = [np.nan,np.nan]<br>                else:<br>                    area,bhk = [ele.text for ele in elements]<br><br>                property = {<br>                    \"name\":name,<br>                    \"location\":location,<br>                    \"price\":price,<br>                    \"area\":area,<br>                    \"bhk\":bhk<br>                }<br>                data.append(property)<br><br>            wait.until(<br>                EC.element_to_be_clickable((By.XPATH, \"//a[normalize-space()='Next Page &gt;']\"))<br>            ).click()<br>            # time.sleep(5)<br>        except :<br>            print(\"Timeout while clicking on \\\"Next Page\\\".\\n\")</pre>\n<pre>time.sleep(3)<br>next_page_button = driver.find_element(By.XPATH,\"//a[normalize-space()='Next Page &gt;']\")</pre>\n<p>Pauses 3 seconds, then tries to find the \u201cNext Page\u201d\u00a0button.</p>\n<pre>driver.execute_script(\"window.scrollBy(0, arguments[0].getBoundingClientRect().top - 100);\", next_page_button)</pre>\n<p>Scrolls the page to the button\u2019s location.</p>\n<h3>clean and Export data as an Excel\u00a0sheet.</h3>\n<p>To clean and export data as an excel, will use Pandas\u00a0library.</p>\n<pre>df_properties = (<br>    pd<br>    .DataFrame(data)<br>    .drop_duplicates()<br>    .apply(lambda col: col.str.strip().str.lower() if col.dtype == \"object\" else col)<br>    .assign(<br>        is_starred = lambda df_:df_.name.str.contains(\"\\n\").astype(int),<br>        name = lambda df_ :(<br>            df_<br>            .name<br>            .str.replace(\"\\n[0-9.]+\",\"\",regex=True)<br>            .str.strip()<br>        ),<br>        location = lambda df_:(<br>            df_<br>            .location<br>            .str.replace(\"chennai\",\"\")<br>            .str.strip()<br>            .str.replace(\",$\",\"\",regex=True)<br>            .str.split(\"in\")<br>            .str[-1]<br>            .str.strip()<br>        ),<br>        price = lambda df_ :(<br>            df_<br>            .price<br>            .str.replace(\"\u20b9\",\"\")<br>            .apply(lambda val: float(val.replace(\"lac\",\"\").strip()) if \"lac\" in val else float(val.replace(\"cr\",\"\").strip())*100)<br>        ),<br>        area = lambda df_ : (<br>            df_<br>            .area<br>            .str.replace(\"sqft\",\"\")<br>            .str.strip()<br>            .str.replace(\",\",\"\")<br>            .pipe(lambda ser:pd.to_numeric(ser))<br>        ),<br>        bhk = lambda df_ : (<br>            df_<br>            .bhk<br>            .str.replace(\"bhk\",\"\")<br>            .str.strip()<br>            .pipe(lambda ser:pd.to_numeric(ser))<br><br>        )<br>    )<br>    .rename(columns={<br>        \"price\":\"price_lakhs\",<br>        \"area\":\"area_sqft\"<br>    })<br>    .reset_index(drop=True)<br>    .to_excel(\"chennai-properties-99acres.xlsx\",index=False)<br>)<br># df_properties.query(\"is_starred == 1\")<br>df_properties </pre>\n<figure><img alt=\"\" src=\"https://cdn-images-1.medium.com/max/1024/1*zN17jzg98zzs_Iflci2D9w.png\"><figcaption>output</figcaption></figure><h3><strong>Summary</strong></h3>\n<p>Here is brief summary of step-by-step process we followed for scraping properties from\u00a099acres.</p>\n<ol>\n<li>We saw websites often restrict access to bots or automated tools like Selenium so we set \u2018<a href=\"https://www.selenium.dev/documentation/webdriver/drivers/options/\">Options\u2019</a> to provide control and flexibility in web automation.</li>\n<li>Visited target URL \u201c<a href=\"https://www.99acres.com./\">https://www.99acres.com</a>\u201d by usingdriver.get(url).</li>\n<li>Attempted to locate a search bar on a web page and then typed the word \u201cChennai\u201d into\u00a0it.</li>\n<li>Not only checked the presence of search button also clicked the\u00a0button.</li>\n<li>Adjusted the budget slider to search the properties up to 5cr\u00a0INR.</li>\n<li>We applied 4 filters\u00a0: Verified, Ready To Move, With Photos and With\u00a0Videos.</li>\n<li>Navigated to each page one by one and extracted the name of property owner, location, the price of property and\u00a0BHK.</li>\n<li>Cleaned and exported the data as excel\u00a0file.</li>\n</ol>\n<h3><strong>References:</strong></h3>\n<p><a href=\"https://www.selenium.dev/documentation/\"><em>The Selenium Browser Automation Project.</em></a></p>\n<p><a href=\"https://www.geeksforgeeks.org/selenium-python-tutorial/\"><em>Selenium Python Tutorial Geeks For\u00a0Geeks.</em></a></p>\n<img src=\"https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=3105102f733b\" width=\"1\" height=\"1\" alt=\"\">\n","enclosure":{},"categories":[]}]}